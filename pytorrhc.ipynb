{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['Dataset']  # Replace with your database name\n",
    "collection = db['audio']\n",
    "\n",
    "# Fetch data\n",
    "documents = collection.find({})\n",
    "\n",
    "# Initialize lists to store features\n",
    "mfccs = []\n",
    "spectral_centroids = []\n",
    "zero_crossing_rates = []\n",
    "\n",
    "# Iterate over documents to extract features\n",
    "for doc in documents:\n",
    "    if 'features' in doc and 'mfccs_stats' in doc['features'] and 'mean' in doc['features']['mfccs_stats']:\n",
    "        mfccs.append(doc['features']['mfccs_stats']['mean'])  # Extracting 20 MFCC mean values\n",
    "    if 'features' in doc and 'spectral_centroid_stats' in doc['features'] and 'mean' in doc['features']['spectral_centroid_stats']:\n",
    "        spectral_centroids.append([doc['features']['spectral_centroid_stats']['mean']])  # Ensuring 2D by wrapping in list\n",
    "    if 'features' in doc and 'zero_crossing_rate_stats' in doc['features'] and 'mean' in doc['features']['zero_crossing_rate_stats']:\n",
    "        zero_crossing_rates.append([doc['features']['zero_crossing_rate_stats']['mean']])  # Ensuring 2D by wrapping in list\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "mfccs = np.array(mfccs)\n",
    "spectral_centroids = np.array(spectral_centroids)\n",
    "zero_crossing_rates = np.array(zero_crossing_rates)\n",
    "\n",
    "# Check and adjust dimensions if necessary\n",
    "if mfccs.ndim == 1:\n",
    "    mfccs = mfccs.reshape(-1, 1)\n",
    "if spectral_centroids.ndim == 1:\n",
    "    spectral_centroids = spectral_centroids.reshape(-1, 1)\n",
    "if zero_crossing_rates.ndim == 1:\n",
    "    zero_crossing_rates = zero_crossing_rates.reshape(-1, 1)\n",
    "\n",
    "# Stack the features to form a feature matrix\n",
    "features = np.concatenate((mfccs, spectral_centroids, zero_crossing_rates), axis=1)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# Example labels array, replace with your actual labels array\n",
    "labels = np.random.randint(2, size=normalized_features.shape[0])  # Random binary labels for demonstration\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "class MusicModel(nn.Module):\n",
    "    def _init_(self, num_features):\n",
    "        super(MusicModel, self)._init_()\n",
    "        self.layer1 = nn.Linear(num_features, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 1)  # Adjust this if your output differs\n",
    "\n",
    "    def forward_model(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "def distributed_enviorment():\n",
    "    # Set up the distributed environment for PyTorch\n",
    "    dist.init_process_group('nccl', init_method='env://')  # Assumes NCCL backend; adjust as needed\n",
    "\n",
    "def create_distributed_model(model, device):\n",
    "    model = model.to(device)\n",
    "    ddp_model = DDP(model, device_ids=[device])\n",
    "    return ddp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming X_train and y_train are your features and labels loaded from previous steps\n",
    "tensor_x = torch.Tensor(X_train)  # transform to torch tensor\n",
    "tensor_y = torch.Tensor(y_train)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x, tensor_y)  # create your dataset\n",
    "my_dataloader = DataLoader(my_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_music_model(ddp_model, dataloader, epochs, device):\n",
    "    optimizer = optim.Adam(ddp_model.parameters(), lr=0.001)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start = time.time()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = ddp_model(inputs)\n",
    "                loss = criterion(outputs, labels.view(-1, 1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            epoch_duration = time.time() - epoch_start\n",
    "            print(f'Epoch {epoch+1}, Loss: {epoch_loss / len(dataloader)}, Duration: {epoch_duration}s')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n",
      "tensor([[0.3158, 0.3915, 0.3024],\n",
      "        [0.3143, 0.5429, 0.4501],\n",
      "        [0.1412, 0.3373, 0.3045]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Set device to CUDA\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    # Set device to CPU\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")\n",
    "\n",
    "# Create a tensor on the selected device\n",
    "x = torch.rand(3, 3).to(device)\n",
    "\n",
    "# Perform some operations\n",
    "y = torch.matmul(x, x)\n",
    "\n",
    "# Print the result\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MusicRecommendationModel(nn.Module):\n",
    "    def _init_(self, num_features):  # Ensure 'num_features' is properly defined as a parameter\n",
    "        super(MusicRecommendationModel, self)._init_()\n",
    "        self.layer1 = nn.Linear(num_features, 512)  # Use 'num_features' to define input size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.layer2 = nn.Linear(512, 256)\n",
    "        self.output_layer = nn.Linear(256, 1)  # Assuming binary output, adjust according to your needs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MusicRecommendationModel.__init__() got an unexpected keyword argument 'num_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m num_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m  \u001b[38;5;66;03m# Set this to the number of features in your dataset\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create an instance of the MusicRecommendationModel with the correct number of input features\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMusicRecommendationModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Wrap the model with DistributedDataParallel\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:434\u001b[0m, in \u001b[0;36mModule.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;66;03m# Backward compatibility: no args used to be allowed when call_super_init=False\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(kwargs):\n\u001b[1;32m--> 434\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    439\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: MusicRecommendationModel.__init__() got an unexpected keyword argument 'num_features'"
     ]
    }
   ],
   "source": [
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# Initialize Distributed Training Environment\n",
    "def setup_distributed_environment():\n",
    "    dist.init_process_group(backend='nccl')  # Make sure to call this only once\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming 'num_features' is known and properly set according to your dataset\n",
    "num_features = 20  # Set this to the number of features in your dataset\n",
    "\n",
    "# Create an instance of the MusicRecommendationModel with the correct number of input features\n",
    "model = MusicRecommendationModel(num_features=num_features)\n",
    "model.to(device)\n",
    "\n",
    "# Wrap the model with DistributedDataParallel\n",
    "model = DDP(model, device_ids=[torch.cuda.current_device()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
